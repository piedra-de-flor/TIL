# 운영 체제
## 운영체제에 대해 아는대로 설명해보세요.
운영체제는 컴퓨터의 하드웨어와 소프트웨어 자원들을 효율적으로 관리하며 작업을 할 수 있는 환경을 제공해주는 시스템 소프트웨어입니다.
예를 들어 프로세스 관리 영역 중의 스케줄링은 여러 응용 프로그램이 동시에 실행되는 상황에서 CPU 자원을 효율적으로 할당하는 역할을 합니다. 이 밖에 운영체제의 대표적인 역할로는 메모리 및 파일 시스템과 같은 저장장치 관리, TCP/IP 및 기타 프로토콜와 관련한 네트워킹, 사용자의 계정 및 접근권한 관리 그리고 기기의 input, output 드라이버를 관리하는 역할이 있습니다.

이러한 기능은 소프트웨어 자원을 효율적으로 활용하여 전체적인 시스템 안정성과 성능을 유지하는 데 도움이 됩니다.

운영체제의 종류에는 Windows, UNIX, LINUX, MacOS, MS-DOS 등이 있습니다.

참고: tech-interview-for-developer : gyoogle github repository

## 시스템 콜에 대해 아는대로 설명해보세요.
시스템 콜은 운영체제와 응용 프로그램 간의 상호작용을 위한 인터페이스로, 응용 프로그램이 운영체제의 기능을 활용할 수 있도록 돕습니다. 이러한 시스템 콜은 프로세스 제어, 파일 조작, 장치 관리, 정보 유지, 통신, 보호 등 여러 유형으로 나뉩니다.

예를 들어 , 파일 조작 시스템 콜은 파일을 열거나, 읽고 쓰는 동작을 수행할 수 있게 합니다. 이러한 시스템 콜은 응용 프로그램이 파일 시스템과 상호작용할 수 있도록 해줍니다.

시스템 콜이 실행되면 프로세스는 사용자 모드에서 커널 모드로 전환됩니다. 이러한 전환은 운영체제의 보호된 영역에 접근하여 필요한 작업을 수행하도록 합니다. 즉, 프로세스가 하드웨어에 직접 접근해서 필요한 기능을 할 수 있도록 도와주는 역할을 합니다.

## Paging이 왜 나오게 되었고, 개념에 대해 설명해 주세요.
Paging은 외부 단편화 문제를 줄이고, 효율적인 메모리 할당을 위한 메모리 관리 기법입니다.

Paging이란 process가 할당받은 메모리 공간을 일정한 page 단위로 나누어, 물리 메모리에서 연속되지 않는 서로 다른 위치에 저장합니다. 각 processs는 주소 변환을 위해 page table을 갖게 되며, 이 page table을 통해 가상 주소가 실제 물리 메모리 주소로 변환됩니다.

## Paging 기법 사용시 발생할 수 있는 메모리 단편화(Memory fragmentation) 문제에 대해 설명해 주세요.
메모리 단편화 문제는 저장 공간이 비효율적으로 관리되어, 용량과 성능이 저하되는 문제입니다. 그중에서 메모리 상의 비어있는 공간의 크기가 작아서, 빈 메모리 공간임에도 활용되지 못하는 문제가 외부 단편화 문제입니다. 반면 프로세스가 필요한 양보다 더 큰 메모리가 할당되어서 메모리 공간이 낭비되는 문제는 내부 단편화 문제입니다.

Paging 기법에서는 각 process의 논리적 주소 공간과 물리적 메모리가 같은 크기의 page 단위로 나누어지기 때문에 외부 단편화 문제가 발생하지 않습니다. 하지만 process 주소 공간의 크기가 page 크기의 배수라는 보장이 없기 때문에, process의 주소 공간 중 가장 마지막에 위치한 page에서는 내부 단편화 문제가 발생할 가능성이 있습니다.

## Paging과 Segmentation의 차이점에 대해 설명해 주세요.
둘 다 연속되지 않는 물리 메모리 공간을 process에 할당하는 메모리 관리 기법입니다. Paging은 일정한 크기인 page 단위로, Segmentation은 code, data, heap, stack과 같이 논리적 의미 단위로 나누는 것이 차이점입니다.

Paging의 경우 메모리 분할 공간이 일정하여 내부 메모리 단편화의 문제가 발생할 수 있고, 이에 반해 Segmentation은 서로 다른 크기의 segment들이 메모리에 적재되고 제거되는 일이 반복되면 외부 메모리 단편화의 문제가 발생할 수 있습니다.

## Multi process에 대해 설명해보세요.
Multi process는 2개 이상의 process가 동시에 실행되는 개념을 나타냅니다. 각 process는 실행파일이 memory에 적재되어 CPU에 의해 독립적으로 실행됩니다. Multi process 환경에서의 동시는 동시성(concurrency)와 병렬성(parallelism) 두 가지를 의미합니다.

동시성은 CPU core가 1개일 때, 여러 process를 짧은 시간동안 번갈아 가면서 연산을 하게 되는 시분할 시스템으로 실행되는 것이고, 병렬성은 CPU core가 여러 개일 때, 각각의 core가 각각의 process를 연산하여 process가 동시에 실행되는 것입니다.

Multi process 환경에서는 프로세스 간 통신과 협력이 중요한 역할을 합니다. 공유 메모리, 메시지 큐의 메커니즘을 활용하여 프로세스 간 데이터 교환과 협력이 이루어집니다. 이러한 방식으로서 다양한 작업을 동시에 처리할 수 있습니다.

## Multi process와 Multi thread의 차이를 설명해보세요.
두 개념 보두 동시성을 달성하는 데 사용되는 주요 방법입니다. Multi thread란 하나의 process가 동시에 여러 개의 일을 수행할 수 있도록 하는 것입니다. 즉, 하나의 process에서 여러 작업을 병렬로 처리하기 위해 Multi thread를 사용합니다. Multi process는 각각 독립된 메모리 공간을 가집니다.

Multi thread는 Multi process보다 적은 메모리 공간을 차지하고 Context Switching 시 캐시 메모리를 초기화할 필요가 없어 속도가 빠릅니다. 하지만 여러 thread가 동일한 자원에 동시 접근 하여 의도치 않은 값을 읽거나 수정하는 동기화 문제와 하나의 thread 장애로 전체 thread가 종료될 위험이 있습니다.
Multi process는 하나의 process가 죽더라도 다른 process에 영향을 주지 않아 안정성이 높습니다. 반면 Multi thread와 달리 process를 생성하고 자원을 할당하는 등의 system call이 있기 때문에 많은 메모리 공간과 CPU 시간을 차지합니다.
따라서 시스템 설게 시 작업의 특성과 환경에 따라 다르게 선택해야 합니다. 예를 들어 웹 서버에서는 Multi process를 사용하여 안정성을 확보하고, 데이터베이스 서버에서는 Multi thread를 활용하여 빠른 응답을 제공하는 것이 효과적일 수 있습니다.
## Multi process 환경에서 process 간 데이터를 어떻게 주고 받는지 설명해보세요.
원칙적으로 process는 독립적인 주소 공간을 갖기 때문에 다른 process의 주소 공간을 참조할 수 없습니다. 하지만 경우에 따라 운영체제는 process 간의 자원 접근을 위한 메커니즘, IPC(Inter Process Communication)를 제공합니다.

이러한 프로세스 간 통신 방법으로는 pipe, 소켓, 공유 메모리 등이 있습니다.
pipe는 단뱡향으로 데이터를 전송할 수 있으며 주로 부모-자식 프로세스 간 통신에 사용됩니다.

소켓은 네트워크 통신을 위한 IPC 방법으로 사용되며, 클라이언트와 서버 사이에서 데이터를 주고 받을 수 있습니다.

공유 메모리는 통신이 아닌, 데이터 자체를 공유하도록 지원합니다. 프로세스 간 메모리 영역을 공유해서 사용하도록 허용해주는 역할을 합니다.

IPC 방법을 선택할 때는 상황에 따라 다릅니다. 파이프는 간단한 통신에, 소켓은 네트워크 통신에 적합합니다. 공유 메모리는 성능을 우선시하고자 할 때 유용합니다. 보안 측면에서는 소켓이나 파이프보다는 공유 메모리가 더 취약할 수 있습니다.

참고: tech-interview-for-developer : gyoogle github repository

## process 생애 주기에 대해 설명해보세요.
하나의 process는 여러 가지 상태를 가지며, 주로 실행-준비-대기 상태 등이 있습니다. process는 처음에 준비 상태에서 시작하여 CPU를 할당 받아 실행 상태로 전환됩니다. 그 후 input output 작업이나 이벤트 발생 등으로 대기 상태에 전환될 수도 있고, 다른 process가 CPU를 요청할 때 준비 상태도 전환될 수 있습니다.

이때 process는 매우 짧은 시간동안 CPU를 점유하여 일정 부분의 명령을 수행하고, 다른 process에게 넘깁니다. 그 후 차례가 되면 다시 CPU를 점유하여 명령을 수행합니다. 따라서 이전에 어디까지 수행했고, register에는 어떤 값이 저장되어 있었는지에 대한 정보가 필요하게 되는데 이런 총제적인 정보가 바로 context입니다. context는 PCB(Process Control Block)에 저장됩니다.

PCB는 운영 체제가 프로세스를 표현한 자료구조입니다. 프로세스 상태, 고유 번호, 다음 실행할 명령어 주소, register 값, 메모리 제한 등 프로세스의 중요한 정보가 담겨 있어 보호된 메모리 영역 안에 저장됩니다.

process끼리 CPU 제어권이 옮겨지는 것을 Context switch라고 합니다. 이때 이전의 프로세스 상태를 PCB에 저장하여 보관하고 새로운 프로세스의 PCB를 읽어서 보관된 상채를 복구하는 작업이 이루어집니다. Context switch의 비용을 최소화하기 위해서는 process 스케줄링 알고리즘의 효율적인 설계와 멀티코어 프로세싱을 활용하는 등의 방법이 사용됩니다.

## deadlock은 언제 발생하게 되나요?
deadlock은 둘 이상의 process나 스레드가 점유하고 있는 자원을 서로 기다릴 때 무한 대기에 빠지는 상황을 말합니다.

dealock은 상호 배제, 점유 대기, 비선점, 순환 대기 조건이 동시에 성립해야 발생합니다. 상호 배제는 한번에 한 process만 점유할 수 있는 상황이고, 점유 대기는 process가 자원을 보유한 상태에서 다른 process가 해당 자원을 추가적으로 기다리고 있는 상황입니다. 비선점은 다른 process가 사용 중인 자원을 강제로 선점할 수 없는 상황이고, 순환 대기는 대기 중인 process들이 순환 형태로 자원을 대기하는 상황을 말합니다.

예를 들어 두 개의 프로세스 A, B가 각각 자원 X, Y를 보유하고, 서로가 가진 자원을 대기하면서 무한 대기 상태에 빠진다고 가정할 수 있습니다. 이때 A는 X를 가지고 있는 동시에 B가 가진 Y를 기다리고 있고, 반대로 B는 Y를 가지고 있는 동시에 A가 가진 X를 기다리고 있어 순환 대기 조건이 성립하게 됩니다.

## deadlock은 어떻게 해결할 수 있나요?
deadlock의 해결방법으로는 무시, 예방, 회피, 탐지-회복이 있습니다.

무시는 deadlock 발생 확률이 낮은 시스템에서 아무런 조치를 취하지 않고 deadlock을 무시하는 방법입니다. 현대 시스템에서는 deadlock이 잘 발생하지 않고, 시스템 성능 저하가 없기 때문에 무시 기법이 많이 사용됩니다.

예방은 deadlock 상태 발생 조건 중 하나를 제거하는 기법입니다. 예를 들어 자원에 고유번호를 할당한 후 순서대로 자원을 요구하는 순환 대기 조건이 성립하지 않도록 하는 것이 가장 현실적입니다. 그러나 자원 사용의 효율성이 떨어지고 비용이 크다는 것이 단점입니다.

회피는 process가 앞으로 자원을 어떻게 요청할 지에 대한 정보를 통해 순환 대기 상태가 발생하지 않도록 자원을 할당하는 기법입니다. 대표적인 예로 은행원 알고리즘, 자원 할당 그래프 알고리즘을 사용하여 자원을 할당하여 deadlock을 회피합니다. 이 기법은 자원 요청에 대한 정보가 미리 알려져 있어야 하는 제약이 있습니다.

마지막으로 탐지-회복은 시스템 검사로 deadlock 발생을 탐지하고, 이를 회복하는 기법입니다. deadlock 상태를 일으킨 프로세스를 종료하거나 할당된 자원을 해제시켜 회복합니다. 이 기법은 예방과 마찬가지로 자원 사용의 효율성이 떨어지고 비용이 크다는 것이 단점입니다.

이러한 방법은 각각의 장단점이 있으며, 상황과 시스템 요구에 따라 적절한 방법을 선택해야 합니다.

## Race Condition에 대하여 간단한 예시를 들어 설명해 주세요.
Race Condition은 여러 프로세스나 스레드가 동시에 공유된 자원을 조작할 때 타이밍에 따라 결과가 달라질 수 있는 상황을 의미합니다.

예를 들어 동시에 실행되는 두 스레드 A, B가 공유 변수 balance에 동시에 접근하며, 각각의 스레드는 데이터에 입금 및 출금하는 로직을 수행한다고 가정하겠습니다. 만약 스레드 A가 balance를 읽고 200을 출금하려는 도중, 스레드 B가 balance를 읽고 100을 입금한다면 서로의 작업이 겹쳐서 balance에 대한 최종값이 예측 불가능해질 수 있습니다.

이러한 Race Condition을 방지하기 위해서는 동기화 메커니즘이 필요합니다. 대표적으로 뮤텍스를 사용할 수 있습니다. 뮤텍스는 상호배제를 제공하여 임계 구역에 대한 동시 접근을 막는 동기화 메커니즘입니다. 뮤텍스는 공유 자원을 점유하는 thread가 lock을 걸면, 다른 thread는 unlock 상태가 될 때까지 해당 자원에 접근할 수 없도록 합니다. 해당 기법을 통해 한 번에 하나의 스레드만이 공유 자원에 안전하게 접근할 수 있도록 만들 수 있습니다.

## 뮤텍스와 세마포어 차이점에 대해 설명해 주세요.
뮤텍스와 세마포어 둘 다 동기화 메커니즘으로, 여러 프로세스 또는 스레드 간에 공유된 자원에 안전하게 접근하기 위해 사용됩니다.

뮤텍스는 mutual exclusion, 상호 배제의 약어로, 임계 구역에 대한 동시 접근을 막는 데 사용됩니다. 공유 자원에 접근할 수 있는 프로세스 및 스레드 수를 1개로 제한합니다. 뮤텍스는 주로 lock, unlock의 두 가지 연산을 통해 구현됩니다.

세마포어는 공유 자원에 대한 접근을 여러 프로세스 또는 스레드로 제한할 수 있습니다. 변수 세마포에 접근 가능한 자원의 수를 저장하고 임계 영역 출입 여부에 따라 해당 변수를 제어합니다. 세마포어는 주로 P(wait), V(signal)의 두 가지 기본 연산을 통해 구현됩니다.

## CPU 스케줄링은 왜 필요하나요?
스케줄링은 프로세스가 생성되고 실행될 떄 필요한 시스템의 여러 자원을 해당 프로세스에게 할당하는 작업을 의미합니다. 실행되고 있는 프로세스에게 CPU가 공평하게 할당되고, 응답 시간과 반환 시간을 최소화하기 위해 필요한 작업입니다. 특히나 다중 프로그래밍 환경에서는 CPU는 한정된 자원이기 때문에 이 작업을 최대한 활용하려 대기 중인 프로세스들이 적절한 시간에 실행되도록 해야합니다.

요약하자면, CPU 스케줄링은 시스템의 공평성, 응답성, 효율성을 향상시키기 위한 핵심적인 관리 작업으로써 필요합니다.

## CPU 스케줄링의 종류와 각 종류 별 예시를 하나 들어주세요.
스케줄링은 우선순위가 높은 프로세스가, 실행되고 있는 프로세스의 CPU를 강제로 뺴앗을 수 있는 여부에 따라 선점, 비선점으로 구분됩니다.

비선점 스케줄링은 프로세스 응답 시간의 예측이 용이하지만, 중요한 작업이 중요하지 않은 작업을 기다리는 경우가 발생할 수 있습니다. 대표적인 예로 First Come First Served가 있습니다. 큐에 도착한 순서대로 CPU가 할당되는 것을 특징으로 가집니다.

선점 스케줄링은 우선순위가 높은 프로세스가 빠르게 처리되지만 많은 오버헤드를 발생시킬 수 있습니다. 대표적인 예로 Round Robin이 있습니다. 앞서 제시한 FCFS에 의해 프로세스들의 보내지면 각 프로세스는 동일한 시간의 최소 단위 시간만큼 CPU를 할당 받습니다. 즉, 할당 시간이 크면 FCFS와 동일하게 작동되고, 작으면 Context Switching이 잦아져서 오버헤드가 증가합니다.

스케줄링은 다양한 방식으로 CPU를 효과적으로 관리하고 각각의 장단점이 있습니다. 그래서 운영체제의 목적, 사용 환경에 따라 선택하는 종류가 달라집니다.